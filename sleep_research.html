<!DOCTYPE HTML>
<html>
	<head>
		<title> Sleep Stage Classification </title>
		<link rel="icon" href="images/pic5.jpg">
		
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	 <style>
    .dynamic-bg {
      background-image: url("images/bg.jpg");
      background-position: center;
      background-repeat: no-repeat;
      background-size: cover;
      background-attachment: fixed;
      height: 100vh;
    }
	.post p {
  text-align: left !important;
}

</style>
</head>

<body class="dynamic-bg">
</body>

				<!-- Header -->
					<header id="header">
						<a class="logo"> Sleep Stage Classification </a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
<!-- 							<li><a href="index.html">Home Page</a></li>
							<li class="active"><a href="about_me.html">About Me</a></li> -->
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/saba-madadi-8a7374256/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
<!-- 							<li><a href="https://t.me/sabamadadi24" class="icon brands fa-telegram"><span class="label">Telegram</span></a></li> -->
							<li><a href="https://github.com/sabamadadi" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
<section class="post" style="text-align: left !important; direction: ltr; margin: 0 auto;">
  <header class="major" style="text-align: left !important;">
<!-- 									<span class="date"> July 17, 2023 </span> -->
									<h3>Advances in Deep Learning for Automatic Sleep Stage Classification: A Comprehensive Survey</h3>

  <h3>Abstract</h3>
  <p>
    Sleep stage classification is a fundamental task in both clinical and research domains of sleep medicine. 
    Manual scoring, though considered the gold standard, is time-consuming, subjective, and requires expertise. 
    The last decade has witnessed the rapid growth of deep learning approaches that can process raw polysomnography (PSG) signals 
    and automatically assign sleep stages with high accuracy. 
    In this survey, we present a structured overview of recent advances in automatic sleep staging with a focus on 
    <b>model architectures, feature engineering strategies, multimodal data integration, dataset utilization, and evaluation methodologies</b>. 
    We review representative models such as <i>DeepSleepNet-Lite, SleePyCo, L-SeqSleepNet, CTCNet, XSleepNet, SleepEGAN</i>, 
    highlighting their innovations, strengths, and limitations. 
    Furthermore, we analyze dataset usage trends, emphasizing the dominance of Sleep-EDF and SHHS. 
    We conclude with a discussion on current challenges — particularly class imbalance, generalizability, interpretability, and real-time deployment — 
    and propose future directions involving self-supervised learning, multimodal fusion, and lightweight architectures for wearable devices.
  </p>

  <h3>1. Introduction</h3>
  <p>
    Sleep plays a critical role in human health, with its disruption linked to neurological disorders, cardiovascular diseases, 
    and reduced cognitive performance. 
    Traditionally, sleep stages are scored in 30-second epochs according to the <b>AASM</b> or <b>R&K</b> guidelines. 
    Manual annotation requires substantial effort and suffers from inter-rater variability. 
    Machine learning initially attempted to automate this process with handcrafted features, 
    but lacked the flexibility to generalize across datasets. 
    The adoption of <b>deep learning</b> — particularly CNNs, RNNs, and Transformers — 
    has enabled end-to-end learning from raw signals and outperformed classical approaches. 
    The purpose of this survey is to provide an in-depth analysis of recent work and to chart possible future research pathways.
  </p>

  <h3>2. Background</h3>
  <h4>2.1 Sleep Architecture and Staging Rules</h4>
  <p>
    Human sleep cycles through five stages: Wake (W), N1, N2, N3 (deep sleep), and REM. 
    N1 is light sleep and notoriously difficult to classify due to its transient characteristics and similarity with Wake/REM. 
    The American Academy of Sleep Medicine (AASM) guidelines standardized the scoring rules used by most studies. 
  </p>

  <h4>2.2 Data Sources</h4>
  <p>
    The gold standard is <b>polysomnography (PSG)</b>, recording EEG, EOG, EMG, ECG, respiratory effort, and oxygen saturation. 
    Recently, <b>wearables</b> such as EEG headbands and PPG-based devices have gained traction for large-scale, real-world monitoring. 
    These developments have encouraged multimodal deep learning methods that integrate multiple physiological channels.
  </p>

  <h3>3. Datasets</h3>
  <p>
    Public datasets have driven advances in this field. The most widely used include:
  </p>
  <ul>
    <li><b>Sleep-EDF</b>: The most cited dataset, widely used for benchmarking.</li>
    <li><b>SHHS</b>: A large cohort study with diverse populations.</li>
    <li><b>MASS</b>: Provides multiple modalities with high-quality annotations.</li>
    <li><b>ISRUC</b>: Includes both healthy and pathological subjects.</li>
    <li><b>MESA, MGH, DREAMS, CAPS</b>: Supplementary datasets focusing on specific conditions or populations.</li>
  </ul>
  <p>
    Surveys show that Sleep-EDF and SHHS dominate research usage, with >60% of studies relying on them. 
    ISRUC and MASS are gaining attention due to their pathological data, enabling better model generalization.
  </p>

  <h3>4. Deep Learning Models</h3>

  <h4>4.1 Convolutional Neural Networks (CNNs)</h4>
  <p>
    CNNs have been the most dominant approach due to their ability to extract time-frequency features from raw EEG. 
    Models like <b>DeepSleepNet-Lite</b> and various CNN-attention hybrids achieve strong performance. 
    They are computationally efficient but limited in modeling long-term temporal dependencies across epochs.
  </p>

  <h4>4.2 Recurrent Neural Networks (RNNs)</h4>
  <p>
    RNNs (especially BiLSTM and GRU) are designed to capture sequential information. 
    <b>L-SeqSleepNet</b> is a prominent example, modeling temporal context effectively. 
    However, RNNs are computationally intensive and prone to vanishing gradients.
  </p>

  <h4>4.3 Transformers and Attention Mechanisms</h4>
  <p>
    Transformers have recently gained popularity, with models like <b>SleePyCo, CTCNet, SleepTransformer</b> 
    leveraging self-attention to capture intra- and inter-epoch dependencies. 
    They offer improved interpretability and generalization but demand significant memory and training data.
  </p>

  <h4>4.4 Hybrid Architectures</h4>
  <p>
    Hybrid models combine CNNs and Transformers (e.g., <b>CTCNet</b>) or incorporate GANs (e.g., <b>SleepEGAN</b>) 
    to augment minority classes. 
    Cross-modal methods (EEG+EOG+EMG) are emerging to exploit multimodal PSG data.
  </p>

  <h4>4.5 Lightweight and Real-Time Models</h4>
  <p>
    Deployment on wearable devices requires efficiency. 
    <b>DeepSleepNet-Lite</b> and microcontroller-based CNN-Transformer models have shown promise 
    in running on low-power devices such as Arduino Nano.
  </p>

  <h3>5. Preprocessing and Feature Engineering</h3>
  <p>
    Strategies vary: some models use raw EEG; others apply preprocessing techniques like band-pass filtering, 
    <b>FFT, STFT, CWT</b>, or artifact removal methods such as ICA and WASR. 
    Recently, <b>self-supervised learning</b> (e.g., ContraWR, NeuroNet) has been explored to pre-train on unlabeled data, 
    reducing dependence on manual feature extraction.
  </p>

  <h3>6. Quantitative Evaluation</h3>
  <p>
    Evaluation metrics include Accuracy, F1-score, and Cohen’s Kappa. Key observations:
  </p>
  <ul>
    <li>CNNs often achieve >90% accuracy on Sleep-EDF but drop in cross-dataset tests.</li>
    <li>Transformers provide a better balance between accuracy and interpretability.</li>
    <li>GAN-based and SSL approaches improve minority class (N1) recognition.</li>
    <li>Class imbalance remains a bottleneck for fair performance across all stages.</li>
  </ul>

  <h3>7. Open Challenges and Future Directions</h3>
  <ul>
    <li><b>Class Imbalance:</b> N1 remains underrepresented, requiring weighted losses or synthetic augmentation.</li>
    <li><b>Pathological Generalization:</b> Most models are trained on healthy populations, limiting clinical applicability.</li>
    <li><b>Real-Time Deployment:</b> Wearable integration demands lightweight, energy-efficient models.</li>
    <li><b>Interpretability:</b> Transformer-based attention aids transparency, but clinical trust requires further validation.</li>
    <li><b>Self-Supervised and Federated Learning:</b> Promising for large-scale and privacy-preserving applications.</li>
    <li><b>Cross-Modal Fusion:</b> Integrating EEG, PPG, respiration, and other signals could improve robustness.</li>
  </ul>

  <h3>8. Conclusion</h3>
  <p>
    Automatic sleep stage classification has rapidly evolved with the adoption of deep learning. 
    CNNs dominate feature extraction, while attention-based Transformers enhance interpretability and sequence modeling. 
    Sleep-EDF and SHHS remain central to benchmarking, but generalization challenges highlight the need for more diverse datasets. 
    Future progress will likely involve <b>self-supervised multimodal models, lightweight architectures for real-time use, 
    and interpretable frameworks</b> for clinical adoption.
  </p>

								
							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<section>
							<form method="post" action="#">
								<div class="image main"><img src="images/pic5.jpg" alt="" /></div>
							</form>
						</section>
						<section class="split contact">
							<section>
								<h3>Email</h3>
								<p>                                                                    
							            <a href="mailto:sa.madadi@mail.sbu.ac.ir">mailto:sa.madadi@mail.sbu.ac.ir</a>
							        </p>  
							</section>
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
									<li><a href="https://www.linkedin.com/in/saba-madadi-8a7374256/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://t.me/sabamadadi24" class="icon brands fa-telegram"><span class="label">Telegram</span></a></li>
							<li><a href="https://github.com/sabamadadi" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</section>
						</section>
					</footer>
				<!-- Copyright -->
					<div id="">
						<ul><li></li><li><a href=""></a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>


