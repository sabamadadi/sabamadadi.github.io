<section id="survey-paper">
  <h2>Survey on Automatic Sleep Stage Classification Using Deep Learning</h2>
  <p><strong>Abstract:</strong> Automated sleep stage classification using polysomnography (PSG) signals, especially EEG, EOG, EMG, and ECG, has advanced significantly in recent years. This survey summarizes state-of-the-art methods, including convolutional neural networks (CNNs), transformers, attention mechanisms, and multi-modal learning, highlighting datasets, preprocessing methods, model architectures, evaluation metrics, and trends.</p>

  <h3>1. Datasets</h3>
  <table>
    <thead>
      <tr>
        <th>Dataset</th>
        <th>Number of Recordings</th>
        <th>Channels</th>
        <th>Scoring Method</th>
        <th>Link</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Sleep-EDF Expanded</td>
        <td>197</td>
        <td>EEG, EOG, EMG</td>
        <td>R&K</td>
        <td><a href="https://www.physionet.org/content/sleep-edfx/1.0.0/">Link</a></td>
      </tr>
      <tr>
        <td>Sleep-EDF</td>
        <td>8</td>
        <td>EEG, EOG, EMG</td>
        <td>R&K</td>
        <td><a href="https://www.physionet.org/content/sleep-edf/1.0.0/">Link</a></td>
      </tr>
      <tr>
        <td>SHHS</td>
        <td>9736</td>
        <td>EEG, EOG, EMG, ECG, airflow</td>
        <td>R&K / AASM</td>
        <td><a href="https://www.physionet.org/content/shhpsgdb/1.0.0/">Link</a></td>
      </tr>
      <tr>
        <td>MASS</td>
        <td>200</td>
        <td>EEG, EOG, EMG</td>
        <td>R&K / AASM</td>
        <td><a href="http://www.ceams-carsm.ca/mass">Link</a></td>
      </tr>
      <tr>
        <td>ISRUC</td>
        <td>100+</td>
        <td>EEG, EOG, EMG</td>
        <td>AASM</td>
        <td>-</td>
      </tr>
      <tr>
        <td>CAP Sleep Database</td>
        <td>108</td>
        <td>EEG, EOG, EMG, respiration</td>
        <td>R&K</td>
        <td><a href="https://physionet.org/content/capslpdb/1.0.0/">Link</a></td>
      </tr>
    </tbody>
  </table>

  <h3>2. Preprocessing Techniques</h3>
  <ul>
    <li><strong>Filtering:</strong> Notch filter to remove 50–60 Hz powerline noise, bandpass filters to retain relevant frequencies.</li>
    <li><strong>Artifact Removal:</strong> Independent Component Analysis (ICA) to remove ocular and muscle artifacts.</li>
    <li><strong>Downsampling:</strong> Reduces computational load (e.g., 200 Hz → 66–100 Hz).</li>
    <li><strong>Epoch Segmentation:</strong> Dividing signals into 30-second epochs.</li>
    <li><strong>Feature Extraction:</strong> Time-domain, frequency-domain (FFT), time-frequency (Wavelet or STFT), and statistical features.</li>
  </ul>

  <h3>3. Model Architectures</h3>
  <h4>3.1 Convolutional Neural Networks (CNNs)</h4>
  <ul>
    <li><strong>SleePyCo:</strong> Feature pyramid + supervised contrastive learning on single-channel EEG; shallow CNN backbone with lateral connections forming a feature pyramid; transformer encoder for sequential EEG patterns.</li>
    <li><strong>DeepSleepNet-Lite:</strong> Parallel small/large filter CNNs with Monte Carlo dropout for uncertainty estimation.</li>
    <li><strong>Wavelet-based CNN:</strong> Spectrogram input to lightweight CNN for improved feature representation.</li>
  </ul>

  <h4>3.2 Recurrent Neural Networks (RNNs) and LSTM</h4>
  <ul>
    <li><strong>L-SeqSleepNet:</strong> Long-sequence modeling with bidirectional LSTM for intra- and inter-subsequence temporal patterns.</li>
    <li><strong>RED:</strong> BLSTM combined with CNN for time-domain or spectrogram EEG event detection.</li>
  </ul>

  <h4>3.3 Transformer-Based Models</h4>
  <ul>
    <li><strong>Cross-Modal Transformers:</strong> Learn intra- and inter-modal attention from multiple physiological channels.</li>
    <li><strong>SleepEGAN & SleepTransformer:</strong> Ensemble or sequence models using attention for sequential EEG pattern learning.</li>
    <li><strong>FPJA-Net & Self-Supervised EEG Models:</strong> Use attention, feature pyramids, and contrastive learning for multi-view representations.</li>
  </ul>

  <h4>3.4 Hybrid and Multi-Modal Models</h4>
  <ul>
    <li><strong>NeuroNet:</strong> Multi-scale 1D ResNet + transformer encoder-decoder + temporal context module.</li>
    <li><strong>MGANet:</strong> Graph neural network with spatial-temporal attention.</li>
    <li><strong>BIOT:</strong> Unified biosignal tokenization for cross-dataset learning.</li>
  </ul>

  <h3>4. Evaluation Metrics</h3>
  <ul>
    <li>Accuracy (%)</li>
    <li>Macro F1-score</li>
    <li>Cohen's kappa (κ)</li>
    <li>Sensitivity & Precision per stage</li>
    <li>Dataset-specific examples: ISRUC-SG1 Accuracy 97.74%, F1 93.75%; Sleep-EDF Accuracy ~96%</li>
  </ul>

  <h3>5. Trends and Observations</h3>
  <ul>
    <li>CNNs are the most dominant architecture, often combined with transformers or attention mechanisms.</li>
    <li>Transformers are increasingly used for sequence modeling and multi-modal attention.</li>
    <li>Sleep-EDF and SHHS dominate dataset usage; ISRUC and MASS supplement validation.</li>
    <li>Single-channel EEG is increasingly used for wearable applications, with lower performance on N1 and REM stages.</li>
    <li>Self-supervised and contrastive learning improves generalization and reduces dependence on labeled data.</li>
  </ul>

  <h3>6. Challenges and Future Directions</h3>
  <ul>
    <li>Class imbalance, especially N1 stage, remains a challenge.</li>
    <li>Generalization across different populations and sleep disorders is limited.</li>
    <li>Wearable EEG devices require adaptation to frontal channels.</li>
    <li>Multi-modal fusion improves accuracy but increases computational complexity.</li>
    <li>Lightweight models like FPJA-Net and CausalAttenNet enable real-time applications.</li>
  </ul>

  <h3>7. References</h3>
  <ul>
    <li>Sleep-EDF Expanded Database: <a href="https://www.physionet.org/content/sleep-edfx/1.0.0/">Link</a></li>
    <li>SHHS PSG Database: <a href="https://www.physionet.org/content/shhpsgdb/1.0.0/">Link</a></li>
    <li>ISRUC Sleep Dataset</li>
    <li>SleePyCo: Automatic sleep scoring with feature pyramid and contrastive learning</li>
    <li>DeepSleepNet-Lite: A simplified automatic sleep stage scoring model with uncertainty estimates</li>
    <li>NeuroNet: Hybrid self-supervised learning for sleep stage classification</li>
    <li>CTCNet, SleepEGAN, FPJA-Net, L-SeqSleepNet (see dataset summaries)</li>
  </ul>
</section>
